\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{listings} % Para bloques de código
\usepackage[spanish]{babel}

\title{H.U.L.K}
\author{Diego Viera, Pablo Gómez, Luis Alejandro Arteaga}
\date{June 2025}

\begin{document}

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{matcom.jpg}
    \label{fig:enter-label}
\end{figure}

\maketitle

\newpage

\tableofcontents

\newpage

\section{Introdución}
Este documento presenta el diseño e implementación de un compilador desarrollado en \textbf{Rust}, utilizando \textbf{LLVM} para la generación de código intermedio y finalmente compilar usando \textbf{clang}. El proyecto abarca las fases esenciales de la construcción de compiladores: desde el análisis léxico-sintáctico hasta la generación de código, aplicando técnicas avanzadas estudiadas en el curso.

El proceso de compilación para HULK sigue una arquitectura por capas que inicia con el archivo principal \texttt{main.rs}. Este componente realiza secuencialmente las siguientes operaciones:
\begin{enumerate}
    \item Lectura del código fuente desde \texttt{script.hulk} como cadena de texto
    \item Ejecución del \texttt{parser} para construir el Árbol de Sintaxis Abstracta (\texttt{AST}) (proceso de lexer en runtime del parser).
\end{enumerate}

Tras superar las fases de análisis sin errores léxicos o sintácticos, el flujo continúa con:
\begin{itemize}
    \item Validación semántica mediante recorrido del \texttt{AST} desde su nodo raíz
    \item Generación de código intermedio(\texttt{LLVM-IR}) tras verificación exitosa
    \item Construcción del compilado final usando \texttt{clang}.
\end{itemize}

El ciclo de compilación finaliza con la generación del archivo \texttt{hulk/output.ll}. La gestión del proceso se simplifica mediante un Makefile con comandos específicos:

\begin{lstlisting}
# Compila el codigo fuente y genera output.ll
make compile

# Ejecuta el compilador LLVM sobre el codigo generado
make execute

# Elimina artefactos de compilacion
make clean
\end{lstlisting}

Este diseño modular permite una transición fluida entre análisis, validación y generación de código, manteniendo una estructura de proyecto clara y mantenible.

\section{Generador de Lexer Basado en Autómatas}

Inspirado en los principios establecidos en \textit{Compilers: Principles, Techniques, and Tools} (el libro del dragón), el generador de lexer de este proyecto se construyó mediante una secuencia de etapas estructuradas que reflejan el flujo clásico del análisis léxico en compiladores. A continuación, se describen los componentes principales y los algoritmos asociados en cada fase del proceso.

\subsection{Construcción del AST de Expresiones Regulares}

El proceso comienza con la definición de un conjunto de nodos del Árbol de Sintaxis Abstracta (AST) para representar expresiones regulares. Estos nodos modelan operadores básicos como:
\begin{itemize}
    \item \textbf{Unión}
    \item \textbf{Clausura}
    \item \textbf{Clausura positiva}
    \item \textbf{Estrella de Kleene}
    \item \textbf{Opcional}
    \item \textbf{Wildcard}
    \item \textbf{Conjunto}
    \item \textbf{Símbolos atómicos} (caracteres literales, rangos, clases de caracteres)
\end{itemize}

Un \textit{parser} utilizamos \textbf{lalrpop} para generar un parser especializado y construir nuestro AST


\subsection{Generación de Autómatas Finitos No Deterministas (NFA)}

Una vez obtenido el AST, se aplica el algoritmo para convertir cada expresión regular en un autómata finito no determinista (NFA). Este método asegura que cada subexpresión se traduzca en una máquina que acepte exactamente el lenguaje definido por ella. Se realizaron test para su chequeo.

\subsection{Composición de un NFA Global}

Luego de construir un NFA por cada expresión regular/token, se unifican en un NFA global que permite identificar múltiples tipos de tokens en una sola pasada. Esto se logra añadiendo un nuevo estado inicial con transiciones $\epsilon$ hacia los estados iniciales de cada NFA individual y se establece una precedencia entre los estados de aceptación, con el fin de resolver conflictos en casos de prefijos comunes, como es el caso de (a) y (a*b).

\subsection{Conversión de NFA a DFA}

El NFA global se convierte en un autómata determinista (DFA) mediante el algoritmo de \textit{construcción del subconjunto}, también conocido como \textit{powerset construction}. Este algoritmo genera un conjunto de estados DFA, donde cada estado representa un conjunto de estados del NFA original.

Cada transición del DFA corresponde a leer un símbolo y moverse al conjunto de estados accesibles desde los actuales (incluyendo la cerradura $\epsilon$).

\subsection{Tokenización con el DFA}

Una vez construido el DFA, se utiliza para recorrer el texto de entrada carácter por carácter. En cada paso:
\begin{enumerate}
    \item Se avanza en el DFA según el símbolo leído.
    \item Se registra el último estado de aceptación alcanzado (si lo hay).
    \item Cuando no hay transición válida:
    \begin{itemize}
        \item Se genera un token si hubo un estado final válido.
        \item Se retrocede hasta ese punto.
        \item Se reinicia el DFA desde el estado inicial.
    \end{itemize}
\end{enumerate}

Esto permite realizar la segmentación léxica del texto de manera eficiente, en tiempo lineal.

\textbf{Algoritmo clave:} simulación de DFA con estrategia de \textit{maximal munch} (registro del estado final más reciente).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{nfa.png}
    \caption{NFA}
    \label{fig:nfa}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{dfa.png}
    \caption{DFA}
    \label{fig:dfa}
\end{figure}


\section{Análisis Léxico}
\textbf{Nota:} Aunque en el repositorio del compilador está implementado un generador de lexer, este no está integrado con el compilador y cumple solo el propósito de demostrar dicho conocimiento.
En la sección actual se explica el proceso de lexing usado para el flujo principal del compilador funcional.

\vspace{1.0cm}

A pesar de que el compilador realizado no utiliza un lexer externo como \texttt{Logos}, \texttt{LALRPOP} puede generar \textbf{internamente} un lexer a partir de las expresiones regulares definidas en \texttt{parser.lalrpop}, no se ha tomado la decisión de implementar el lexer por separado sino que esto ocurra durante el mismo parsing. Este proceso funciona así:

\begin{itemize}
    \item \textbf{Definición de terminales:}
    Al comienzo del archivo, se definen terminales como \texttt{Identifier}, \texttt{Num}, \texttt{Str}, etc., utilizando regexes (por ejemplo, \texttt{r"[A-Za-z][A-Za-z\_0-9]*"} para identificadores) y literales (por ejemplo, \texttt{"function"} para palabras clave).

    \item \textbf{Generación automática del lexer:}
    LALRPOP toma todas esas definiciones y genera un lexer que, en tiempo de ejecución, escanea el input caracter por caracter, buscando siempre la coincidencia más larga entre patrones; si un literal y un regex empatan en longitud, el literal tiene prioridad.
    .
    \item \textbf{Proceso de tokenización:}
    Se omiten espacios y comentarios. El lexer produce tokens como \texttt{(String, Span)} o \texttt{(OperatorToken, Span)} según las reglas. Los literales, palabras reservadas, símbolos de operadores, regexes, actúan como terminales, es decir operan sin conocimiento del resto de la gramática: sólo agrupan texto en tokens .
\end{itemize}

\section{Tokens y posicionamiento con Span}
El archivo \texttt{tokens.rs} define los distintos tipos de tokens que se utilizan durante el análisis léxico y sintáctico. Estos tokens se agrupan en tres enumeraciones principales:
\begin{itemize}
    \item \texttt{KeywordToken:} representa palabras clave del lenguaje como \texttt{if, while, function}, entre otras.
    \item \texttt{OperatorToken:} incluye todos los operadores del lenguaje, como \texttt{+, -, ==, :=,} etc.
    \item \texttt{DelimiterToken:} agrupa los símbolos de puntuación como paréntesis, comas, puntos y coma, y flechas (\texttt{=>}).
\end{itemize}

\subsection{Span}
Cada token es acompañado por una estructura llamada \texttt{Span}, la cual contiene las posiciones de inicio y fin del token dentro del código fuente \textbf{(medidas en offsets de byte)}. Esta información es esencial para mantener un seguimiento preciso de la ubicación de cada elemento del programa.
\vspace{0.25cm}

El \texttt{Span} es generado automáticamente por \texttt{LALRPOP} en el archivo \texttt{parser.lalrpop}, utilizando las anotaciones \texttt{@L} y \texttt{@R} que corresponden a los \texttt{offsets} de los \texttt{tokens}. Gracias a esto, el \texttt{AST} generado por el compilador conserva metadatos de ubicación en todos sus nodos.
\vspace{0.25cm}

Por último, esta información es fundamental para el archivo \texttt{parser\_w\_errors.rs}, que aprovecha los \texttt{Span} para generar mensajes de error sintáctico detallados y amigables, indicando la línea, columna y contexto exacto en el que ocurre un problema de análisis.

\section{Análisis Sintáctico}
\subsection{Tipo de Parser}
\begin{itemize}
    \item Por defecto, \texttt{LALRPOP} genera un parser de tipo \texttt{LR(1)} (específicamente con una variante llamada \texttt{lane table}, más compacta).
    \item Esto significa un análisis ascendente, con un símbolo de \texttt{lookahead}, garantizando un parse completo y eficiente \texttt{O(n)} sin backtracking.
\end{itemize}

\subsection{Proceso en \texttt{parser.lalrpop}}
\begin{itemize}
    \item Definición de la gramática \texttt{CFG} en secciones como \texttt{Program, Statement, Expr,} etc., donde se mezclan reglas no terminales y acciones semánticas (constructores de \texttt{AST}).
    \item \texttt{LALRPOP} construye internamente un autómata \texttt{LR(0)}, calcula conjuntos \texttt{LR(1)}, y genera tablas de parsing (\texttt{shift/reduce}).
    \item Se genera código Rust con funciones que emplean un stack de estados:
        \begin{itemize}
            \item Operaciones \texttt{shift} (empujar token al stack).
            \item Operaciones \texttt{reduce} (aplicar una regla, armar un \texttt{AST}).
            \item Estado \texttt{accept} cuando termina.
        \end{itemize}
    \item Este parser se invoca dentro del wrapper \texttt{parser\_w\_errors.rs}.
\end{itemize}

\subsection{Manejo de Errores Sintácticos (\texttt{parser\_w\_errors.rs})}
En lugar de usar el parser directamente, se envuelve en un wrapper para generar mensajes de error más humanos:
\begin{itemize}
    \item Captura errores como \texttt{InvalidToken, UnrecognizedToken, UnrecognizedEof, ExtraToken,} etc.
    \item Utiliza información de posición \texttt{(Span, offset)} y funciones como \texttt{get\_line\_context, build\_caret\_point,} etc.
    \item Genera un mensaje con la línea, columna, y una flecha (\texttt{\textasciicircum\ldots}) para mostrar el lugar del error con un snippet.
    \item Convierte internamente tokens inesperados en mensajes.
\end{itemize}

\section{Análisis Semántico}
El análisis semántico en nuestro compilador está gestionado por la estructura \texttt{SemanticAnalyzer}, definida en \texttt{semantic\_analyzer.rs}. Este analizador implementa el patrón \texttt{Visitor} para recorrer el \texttt{AST} e ir aplicando validaciones semánticas nodo por nodo. Para llevar a cabo este proceso, el SemanticAnalyzer mantiene:

\begin{itemize}
\item Un contexto semántico (\texttt{SemanticContext}) que guarda información sobre los símbolos visibles (variables, funciones declaradas, tipos definidos y el tipo o función actual en análisis).

\item Una pila de contextos para simular los distintos ámbitos (\texttt{scopes}).

\item Una lista de errores semánticos (\texttt{Vec<SemanticError>}) recolectados durante el análisis.

\item Un árbol de tipos (\texttt{TypeTree}) para verificar compatibilidad entre tipos definidos por el usuario o nativos.
\end{itemize}

\subsection{Tipos de Errores Semánticos}
Los errores semánticos se representan como variantes del enum \texttt{SemanticError}, definido en \texttt{semantic\_errors.rs}, y cada uno incluye un mensaje personalizado y un \texttt{Span} con la posición del error en el código fuente para su posterior reporte. Los principales errores que se detectan son:

\begin{itemize}
    \item \texttt{DivisionByZero:} Se detecta una división por cero en tiempo de compilación.

    \item \texttt{UndefinedIdentifier:} Se usa un identificador que no ha sido declarado en el ámbito actual.

    \item \texttt{RedefinitionOfVariable / RedefinitionOfFunction / RedefinitionOfType:} Se intenta declarar una variable, función o tipo con un nombre ya existente en el mismo contexto.

    \item \texttt{UndeclaredFunction:} Se llama a una función que no ha sido definida previamente.

    \item \texttt{InvalidArgumentsCount:} El número de argumentos en una llamada a función no coincide con el esperado.

    \item \texttt{InvalidTypeArgument / InvalidTypeArgumentCount:} El tipo de uno o más argumentos no coincide con la firma esperada de la función o tipo, o se pasan demasiados/pocos argumentos genéricos.

    \item \texttt{InvalidFunctionReturn:} El tipo retornado por una función no coincide con su declaración.

    \item \texttt{InvalidBinaryOperation / InvalidUnaryOperation:} Operaciones entre tipos incompatibles o inválidas.

    \item \texttt{InvalidConditionType:} La condición de una estructura \texttt{if, while} o similar no tiene un tipo \texttt{booleano}.

    \item \texttt{UndefinedType:} Se hace referencia a un tipo no declarado.

    \item \texttt{InvalidTypeFunctionAccess / InvalidTypeProperty\\ / InvalidTypePropertyAccess:} Se accede a métodos o propiedades inexistentes o privadas en un tipo definido por el usuario.

    \item \texttt{CycleDetected:} Se detecta una dependencia cíclica entre definiciones de tipos (herencia).

    \item \texttt{InvalidPrint / InvalidIterable:} Intentos de imprimir o iterar sobre elementos no válidos.
\end{itemize}

Todos estos errores se reportan mediante el método \texttt{report}, que imprime un mensaje detallado con el contexto del código y una flecha que apunta al lugar exacto del problema, facilitando la depuración por parte del usuario.

\subsection{Explicación de \texttt{returned\_types.rs}}
Este archivo define dos estructuras clave:
\begin{itemize}
\item \textbf{FunctionInfo}: contiene el nombre de una función, su lista de argumentos con sus tipos y su tipo de retorno. Se utiliza para validar llamadas a funciones.
\item \textbf{SemanticContext}: estructura mutable que se actualiza durante el recorrido del AST, donde se almacenan:
\begin{itemize}
\item \texttt{symbols}: tabla de variables (nombre $\rightarrow$ tipo).
\item \texttt{declared\_functions}: funciones ya definidas.
\item \texttt{declared\_types}: tipos definidos por el usuario.
\end{itemize}
\item \texttt{current\_type} y \texttt{current\_function}: ayudan a contextualizar errores dentro de clases o funciones específicas.
\end{itemize}

\subsection{Estructura y uso del módulo \texttt{types\_tree} en el análisis semántico}

El módulo \texttt{types\_tree} es uno de los pilares del sistema de tipos del compilador. Su objetivo es representar y gestionar la jerarquía de tipos definidos en el lenguaje, tanto los tipos básicos incorporados como aquellos definidos por el usuario. Este módulo permite validar herencias, acceder a métodos y atributos, y detectar errores semánticos relacionados con el sistema de tipos durante el análisis del \texttt{AST}.

\subsubsection*{Representación de los Tipos: \texttt{TypeNode}}

Cada tipo del lenguaje es representado por un nodo (\texttt{TypeNode}) que contiene la siguiente información:

\begin{itemize}
    \item \texttt{type\_name}: nombre del tipo.
    \item \texttt{params}: parámetros definidos para la construcción del tipo.
    \item \texttt{depth}: profundidad del tipo en la jerarquía (útil para determinar el ancestro común más cercano).
    \item \texttt{parent} y \texttt{children}: relaciones de herencia con otros tipos.
    \item \texttt{variables}: mapa de atributos (nombre $\rightarrow$ tipo).
    \item \texttt{methods}: mapa de métodos asociados al tipo.
\end{itemize}

Este nodo también ofrece métodos auxiliares para agregar atributos, métodos, definir la herencia y acceder a métodos mediante \texttt{get\_method}.

\subsubsection*{Estructura General del Árbol: \texttt{TypeTree}}

El árbol de tipos (\texttt{TypeTree}) es la estructura central que mantiene todos los \texttt{TypeNode}. Este árbol tiene un nodo raíz predefinido llamado \texttt{"Object"}, y al inicializarse se agregan también los tipos primitivos del lenguaje: \texttt{String}, \texttt{Number}, \texttt{Boolean} y un tipo especial \texttt{Unknown}.

Los métodos más relevantes del árbol son:

\begin{itemize}
    \item \texttt{add\_type}: agrega un nuevo tipo al árbol, asociándolo a su padre (si existe).
    \item \texttt{get\_type}: permite obtener información de un tipo por su nombre.
    \item \texttt{find\_method}: busca recursivamente un método en un tipo y sus ancestros.
    \item \texttt{is\_ancestor}: comprueba si un tipo es ancestro de otro.
    \item \texttt{find\_lca}: encuentra el ancestro común más cercano entre dos tipos.
    \item \texttt{check\_cicle}: detecta ciclos de herencia ilegales (herencia circular).
\end{itemize}

\subsubsection*{Uso durante el Análisis Semántico}

Durante el análisis semántico, el \texttt{TypeTree} es utilizado de las siguientes formas clave:

\begin{enumerate}
    \item \textbf{Verificación de herencia válida y sin ciclos.} Cuando se declara un nuevo tipo, se inserta en el \texttt{TypeTree}. Posteriormente se invoca \texttt{check\_cicle} para detectar si existe un ciclo de herencia. En caso de encontrar uno, se genera el error semántico \texttt{CycleDetected}.

    \item \textbf{Propagación y herencia de métodos.} Cuando se accede a un método en una expresión de tipo (\texttt{type.method()}), se llama a \texttt{find\_method}. Si el método no se encuentra en el tipo directamente, se busca en sus ancestros. Si no se encuentra en ningún lugar, se lanza el error \texttt{InvalidTypeFunctionAccess}.

    \item \textbf{Acceso a propiedades y atributos.} Cuando se accede a una propiedad (\texttt{type.prop}), se consulta el \texttt{variables} del \texttt{TypeNode} correspondiente. Si no existe la propiedad, se lanza el error \texttt{InvalidTypeProperty}. Si existe pero no es accesible (por ejemplo, si es privada), se lanza \texttt{InvalidTypePropertyAccess}.

    \item \textbf{Determinación del tipo resultante entre operaciones.} El árbol permite usar la función \texttt{find\_lca} para determinar el ancestro común entre dos tipos, lo cual es útil cuando se necesitan unificar tipos (por ejemplo, en operaciones ternarias o conversiones implícitas).

    \item \textbf{Resolución de tipos en expresiones \texttt{new}.} Cuando se instancia un nuevo objeto con \texttt{new}, se verifica que el tipo exista (\texttt{get\_type}), y que se le pasen los argumentos correctos. En caso de errores, se lanza \texttt{UndefinedType} o \texttt{InvalidTypeArgumentCount}.
\end{enumerate}

\section{Generación de código con LLVM}

La etapa final del proceso de compilación corresponde a la generación de código intermedio en formato LLVM. 

El enfoque de esta sección no se centra en los detalles sintácticos específicos del lenguaje intermedio, 
sino en los principios fundamentales y abstracciones clave que permiten traducir construcciones de alto 
nivel propias de HULK a una representación intermedia ejecutable. Se explican los mecanismos de transformación 
que puentean la brecha entre un lenguaje orientado a expresiones complejas y su equivalente en LLVM-IR.

El proceso de generación de código LLVM sigue un flujo estructurado que aprovecha el \textbf{Árbol de Sintaxis Abstracta (AST)} ya validado en fases anteriores. La estrategia central se basa en el \textbf{patrón Visitor}, que permite recorrer el AST de manera sistemática para emitir el código equivalente en LLVM-IR.

\subsection*{Flujo Principal}
\begin{enumerate}
    \item \textbf{Preparación del entorno}: Inicialización de módulos, funciones y variables globales en LLVM
    
    \item \textbf{Procesamiento de definiciones}:
    \begin{itemize}
        \item Generación de estructuras para tipos personalizados
        \item Creación de prototipos de funciones
    \end{itemize}
    
    \item \textbf{Generación del cuerpo principal}:
    \begin{itemize}
        \item Traducción de expresiones en la función \texttt{main} de hulk
        \item Manejo de estructuras de control y llamadas a funciones
    \end{itemize}
\end{enumerate}

\subsection*{Mecanismo de Traducción}

La implementación sigue estos principios fundamentales:

\begin{itemize}
    \item Cada nodo del AST implementa el método \texttt{accept(Visitor)}
    
    \item El Visitor contiene la lógica específica para:
    \begin{itemize}
        \item \textit{Nodos de declaración}: Generan estructuras globales
        \item \textit{Nodos de expresión}: Producen código ejecutable
    \end{itemize}
    
    \item Las anotaciones de tipos añadidas durante el análisis semántico:
    \begin{itemize}
        \item Determinan las firmas de funciones en LLVM
        \item Especifican conversiones de tipo implícitas
        \item Guían la selección de operaciones primitivas
    \end{itemize}
\end{itemize}

\subsection{Manejo de Variables}

\subsubsection{Declaración y Asignación:}

La reserva de memoria para variables locales se realiza en tiempo de ejecución mediante la instrucción \texttt{alloca}, que asigna espacio en el stack. Las operaciones de escritura y lectura de valores se efectúan utilizando las instrucciones \texttt{store} y \texttt{load} respectivamente.

Un registro de símbolos gestiona el contexto de ejecución, estableciendo una correspondencia entre cada identificador de variable y su ubicación en memoria dentro del ámbito correspondiente.

\subsubsection{Ámbito y Visibilidad:}

El sistema de símbolos implementa múltiples niveles de ámbito (scopes), permitiendo:
\begin{itemize}
    \item Declaraciones locales (dentro de funciones, bloques de código y estructuras de control)
    \item Variables globales (accesibles desde cualquier punto del programa)
    \item Reutilización de identificadores en ámbitos internos (shadowing)
    \item Resolución de nombres mediante búsqueda jerárquica en ámbitos anidados
\end{itemize}

La gestión de la jerarquía de ámbitos se implementa mediante una pila dinámica que se actualiza automáticamente al entrar y salir de diferentes contextos léxicos.

\subsection{Manejo de Funciones}

\subsubsection{Declaración de Funciones:}

El nodo \texttt{FunctionDefNode} representa la definición de una función. Su conversión a LLVM IR comprende las siguientes etapas:
\begin{enumerate}
    \item Especificación del tipo de retorno y los tipos de los parámetros
    \item Instanciación de un nuevo objeto \texttt{llvm}
    \item Creación del bloque básico inicial
    \item Asignación de identificadores a parámetros y registro en la tabla de símbolos
    \item Generación del contenido funcional con gestión del flujo de control y entorno local
\end{enumerate}

\subsubsection{Llamadas a Funciones:}

Las invocaciones funcionales se gestionan mediante el nodo \texttt{FunctionCallNode}, ejecutando estas operaciones:
\begin{itemize}
    \item Evaluación secuencial de los argumentos proporcionados
    \item Comprobación de conformidad de tipos entre argumentos y parámetros
    \item Generación de la instrucción \texttt{call}
    \item Recuperación del valor de retorno (cuando aplica) y asignación en el contexto actual
\end{itemize}

\subsubsection{Ciclos (\texttt{WhileNode,ForNode})}

El sistema implementa estructuras de repetición con gestión explícita de condición e iteración. La traducción general comprende:
\begin{itemize}
    \item Bloque para evaluación de la condición
    \item Bloque para ejecución del cuerpo iterativo
\end{itemize}

\subsection{Sistema de Tipos}

\subsubsection{Tipos Básicos}

Se incluye soporte para los siguientes tipos primitivos:
\begin{itemize}
    \item Number (\texttt{i32}, \texttt{i64}, \texttt{float}, \texttt{double})
    \item Boolean (\texttt{i1})
    \item String (representados como punteros a \texttt{ptr})
\end{itemize}

\subsubsection{Tipos Personalizados (\texttt{TypeDefNode})}

El mecanismo habilita la definición de tipos definidos por el usuario, con funcionalidades para:
\begin{itemize}
    \item Atributos estáticos y dinámicos
    \item Métodos asociados (implementados mediante funciones con primer parámetro tipo instancia)
    \item Relaciones de herencia y composición
\end{itemize}

\subsubsection{Operaciones sobre Tipos}

\paragraph{Acceso a Atributos (\texttt{TypePropAccessNode})}:

Se emplean instrucciones \texttt{getelementptr} (GEP) para determinar el desplazamiento del atributo dentro de la estructura. Posteriormente, se utiliza una instrucción \texttt{load} para recuperar su valor almacenado.

\paragraph{Modificación de Atributos} :

El procedimiento comprende:
\begin{itemize}
    \item Cómputo de la dirección mediante GEP
    \item Comprobación de tipos del valor asignado
    \item Emisión de la instrucción \texttt{store} para actualizar el atributo
\end{itemize}

\end{document}
